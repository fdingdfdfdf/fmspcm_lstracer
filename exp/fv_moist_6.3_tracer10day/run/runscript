#!/bin/csh -f
#SBATCH --job-name=fmsRunTest
#SBATCH --output=fms.out
#SBATCH --error=fms.err
#SBATCH --nodes=12
#SBATCH --ntasks-per-node=32
#SBATCH -t 6-01:00
#SBATCH -p huce_intel
#SBATCH --mem-per-cpu=4000

# === Default test run script for idealized_moist GCM ===

# See description at run_test.readme

# Ian Eisenman, Yohai Kaspi, Tim Merlis, April 2011

#change the working directory (default is home directory)                   
#cd $PBS_O_WORKDIR
#
# load some modules to get everything in the path:

set run_name     = test                              # label for run; output dir and working dir are run_name specific
set run_script   = $cwd/run_${run_name}              # path/name of this run script (for resubmit)
set exp_home     = $cwd:h                            # directory containing run/$run_script and input/
set exp_name     = $exp_home:t                       # name of experiment (i.e., name of this model build)
set fms_home     = $cwd:h:h:h  #/idealized_moist        # directory containing model source code, etc, usually /home/$USER/fms/idealized_moist

set days            = 200                           # length of integration
set runs_per_script = 10                            # number of runs within this script
set num_script_runs = 1                             # how many times to resubmit script to queue
#main_nml
set radius = 6371e3
set ps0    = 1e5
set solar  = 1367.1 #1093.
set nS     = 20 #00 
set ngas   = 2 #radiatively active: 1 is variable 
set mCO2   = 400e-6
set omega  = 7.272e-6 #7.292e-5  

set echo 
echo "*** Running ${run_script} on $HOSTNAME ***"
date

#--------------------------------------------------------------------------------------------------------

#source /etc/profile.d/env-modules.csh
#module load intel/intel-11
#module load mpich/intel-11

echo "MPI Used:" `which mpirun`

#set NPROCS=`wc -l < $PBS_NODEFILE`
#echo This job has allocated $NPROCS cpus
#set NPROCS=15
#--------------------------------------------------------------------------------------------------------

limit stacksize unlimited

# set initial directory structure
set fms_tmp     = /n/scratchlfs02/wordsworth_lab/fding/fms_tmp
set fms_output  = /n/scratchlfs02/wordsworth_lab/fding/fms_output
set scratch_dir = /n/scratchlfs02/wordsworth_lab/fding/${exp_name}/${run_name}  # scratch directory on specific compute node (faster read/write)
#set fms_tmp     = /n/wordsworth_lab/fding/fms_tmp
#set fms_output  = /n/wordsworth_lab/fding/fms_output
#set scratch_dir = /n/wordsworth_lab/fding/${exp_name}/${run_name}  # scratch directory on specific compute node (faster read/write)
if ( ! -d $fms_tmp )    mkdir -p $fms_tmp
if ( ! -d $fms_output ) mkdir -p $fms_output

cd $exp_home

# define variables
set tmpdir      = $fms_tmp/${exp_name}                    # temporary directory for model workdir, output, etc
set run_dir     = $tmpdir/$run_name                       # tmp directory for current run
set workdir     = $run_dir/workdir                        # where model is run and model output is produced
set output_dir  = $run_dir/output                         # output directory will be created here

set platform    = ifc                                     # a unique identifier for your platform
# note the following init_cond's are overwritten later if reload_commands exists
set init_cond   = ""
#set init_cond   = /n/scratchlfs/wordsworth_lab/fding/fms_tmp/fv_moist_2_bm/test/output/restart/day2000h00.cpio
#set init_cond = $cwd/run/day0250h00.cpio

set pathnames   = $exp_home/input/path_names              # path to file containing list of source paths
set namelist    = $exp_home/input/namelists               # path to namelist file
set fieldtable  = $exp_home/input/field_table             # path to field table (specifies tracers)
set execdir     = $tmpdir/exe.fms                         # where code is compiled and executable is created
set diagtable   = $exp_home/input/diag_table              # path to diagnostics table
set mppnccombine = $tmpdir/mppnccombine.$platform         # path to executable mppnccombine
set template    = $fms_home/bin/mkmf.template.${platform} # path to template for your platform
set mkmf        = $fms_home/bin/mkmf                      # path to executable mkmf
set sourcedir   = $fms_home/src                           # path to directory containing model source code
set time_stamp  = $fms_home/bin/time_stamp.csh            # generates string date for file name labels
setenv PPDIR  $fms_home/postprocessing     # path to directory containing postprocessing source code and grid data for fregrid_parallel

#set scratch_dir = /n/scratchlfs/wordsworth_lab/fding/${exp_name}/${run_name}  # scratch directory on specific compute node (faster read/write)
set input_dir   = ${scratch_dir}/combine                  # directory where combined netcdf files are written
set data_expdir = $fms_output/$exp_name                   # path to output directory per experiment
set data_dir    = $fms_output/$exp_name/$run_name         # path to output directory per run

set ireload     = 1                                       # counter for resubmitting this run script
set irun        = 1                                       # counter for multiple model submissions within this script
#--------------------------------------------------------------------------------------------------------

# if exists, load reload file 

set reload_file = ${run_dir}/reload_commands

if ( -d $run_dir )  then
  if ( -f $reload_file ) then
     # set irun, ireload, init_cond
#     source $reload_file
  endif
endif

#--------------------------------------------------------------------------------------------------------

# setup directory structure
if ( ! -d $execdir ) mkdir -p $execdir
if ( ! -d $run_dir ) mkdir -p $run_dir
if ( ! -e $workdir ) then
  mkdir $workdir $workdir/INPUT $workdir/RESTART
else
  rm -rf $workdir
  mkdir $workdir $workdir/INPUT $workdir/RESTART
  echo "WARNING: Existing workdir $workdir removed."
endif

if ( ! -d $output_dir )  then
  mkdir -p $output_dir
  mkdir -p $output_dir/combine
  mkdir -p $output_dir/logfiles
  mkdir -p $output_dir/restart
endif

if ( ! -d  $data_expdir )  mkdir -p $data_expdir
if ( ! -d  $data_dir ) then
  mkdir -p $data_dir
  mkdir -p $data_dir/history
  mkdir -p $data_dir/logfiles
  mkdir -p $data_dir/restart
endif

#--------------------------------------------------------------------------------------------------------

# compile mppnccombine.c, needed only if $npes > 1
#if ( ! -f $mppnccombine ) then
#  gcc -O -o $mppnccombine -I$fms_home/bin/nc_inc -L$fms_home/bin/nc_lib $fms_home/postprocessing/mppnccombine.c -lnetcdf
#endif

#--------------------------------------------------------------------------------------------------------

# compile the model code and create executable

# append fms_home (containing netcdf libraries and include files) to template
#/bin/cp $template $workdir/tmp_template
#echo "fms_home = $fms_home" >> $workdir/tmp_template

# Prepend fortran files in srcmods directory to pathnames.
# Use 'find' to make list of srcmod/*.f90 files. mkmf uses only the first instance of any file name.
#cd $sourcedir
#find $exp_home/srcmods/ -maxdepth 1 -iname "*.f90" -o -iname "*.inc" -o -iname "*.c" -o -iname "*.h" > $workdir/tmp_pathnames
#echo "Using the following sourcecode modifications:"
#cat $workdir/tmp_pathnames
#cat $pathnames >> $workdir/tmp_pathnames

#cd $execdir

#$mkmf -p fms.x -t $workdir/tmp_template -c "-Duse_libMPI -Duse_netCDF -DUSE_LIMA -DSPMD -DLAND_BND_TRACERS" -a $sourcedir $workdir/tmp_pathnames $sourcedir/shared/include $sourcedir/shared/mpp/include

#$mkmf -p fms.x -t $workdir/tmp_template -c "-Duse_libMPI -Duse_netCDF -DSPMD" -a $sourcedir $workdir/tmp_pathnames $sourcedir/shared/mpp/include $sourcedir/shared/include

#make -f Makefile

cd $workdir/INPUT

#--------------------------------------------------------------------------------------------------------

# set initial conditions and move to executable directory

if ( $init_cond != "" ) then
  cp $init_cond $init_cond:t
  cpio -iv  < $init_cond:t
  rm -f $init_cond:t
endif

#--------------------------------------------------------------------------------------------------------

#  --- begin loop over $irun ---                                     
while ($irun <= $runs_per_script)

    cd $workdir  

    # set run length and time step, get input data and executable
    if ( $ireload == 1 && $irun == 1 ) then
      cat > input.nml <<EOF
	&main_nml
         days   	= $days,
         dt_atmos 	= 300,
	 omega  = $omega,
         radius = $radius,
         ps0 	= $ps0,
         nS  	= $nS,
	 datadir 	= '~/lbldata/',
	 deltat_rad     =  7200  /

        &mixed_layer_nml
         depth       = 10.0,
         evaporation = .true. /
EOF
    else
      cat > input.nml <<EOF
	&main_nml
         days   	= $days,
         dt_atmos 	= 300,
         omega  = $omega,
	 radius = $radius,
	 ps0 	= $ps0,
	 nS  	= $nS,
	 datadir	= '~/lbldata/',
	 deltat_rad     =  7200  /

        &mixed_layer_nml
         depth       = 1.0,
         evaporation = .true. /
EOF
    endif

    cat >> input.nml <<EOF

      &radiance_nml
	stellar_blackbody = .true.,
	gray_debug      = .true.,
	tidal_lock      = .true., 
        solar_constant  = $solar,
	mCO2 		= $mCO2,
	nTem		= 1,
	nAng		= 1,
        nGas            = $ngas /

EOF

    cat $namelist >> input.nml
    cp $diagtable $workdir/diag_table
    cp $fieldtable field_table
    cp $execdir/fms.x fms.x

    cp input.nml $run_dir
    #--------------------------------------------------------------------------------------------------------
    # run the model with mpirun
    # mpirun -np $NPROCS -machinefile $TMPDIR/machines ${workdir}/fms.x
    mpirun -np $SLURM_NTASKS ${workdir}/fms.x
  
    #--------------------------------------------------------------------------------------------------------

    #   --- generate date for file names ---

    set date_name = `$time_stamp -eh`
    if ( $date_name == "" ) set date_name = tmp`date '+%j%H%M%S'`
    if ( -f time_stamp.out ) rm -f time_stamp.out

    #--------------------------------------------------------------------------------------------------------

    #   --- move output files to their own directories and combine on scratch (faster) ---

    mkdir $output_dir/combine/$date_name

    foreach ncfile ( `/bin/ls *.nc *.nc.????` )
	mv $ncfile $output_dir/combine/$date_name/$date_name.$ncfile
    end

    mkdir -p ${input_dir}
    cd ${scratch_dir}
    foreach ncfile (`/bin/ls $output_dir/combine/${date_name}/${date_name}.*.nc.0000`)

    mv $ncfile:r.???? ${scratch_dir}
    set ncfile_tail = $ncfile:t
    rm -f $ncfile_tail:r
    $mppnccombine $ncfile_tail:r
    if ($status == 0) then
	mv $ncfile_tail:r ${input_dir}
	echo "$ncfile:r combined in ${scratch_dir} on $HOSTNAME"
    endif
    rm -f $ncfile_tail:r.????
    end

#--------------------------------------------------------------------------------------------------------
#setenv NC_BLKSZ 64K
#setenv NETCDFPATH ${NETCDF_HOME}
#setenv NETCDFPATH /n/sw/fasrcsw/apps/MPI/intel/15.0.0-fasrc01/openmpi/1.8.7-fasrc01/netcdf/4.2-fasrc01 
#gmake -j 6 -f $PPDIR/Make_fregrid_parallel
#if ( $status != 0 ) exit
#--------------------------------------------------------------------------------------------------------
#mv fregrid_parallel ${input_dir}
cp $PPDIR/fregrid_parallel ${input_dir} 
cd ${input_dir}
# Interpolate data to lat-lon grid
set diagFiles = (*.tile1.nc)
set latlonfiles = ()
cp $PPDIR/horizontal_grid.tile?.nc .
cp $PPDIR/C48_mosaic.nc .
foreach File ($diagFiles)
  set variables = (`ncdump -h $File | grep 'grid_yt, grid_xt' | awk '{print $2}' | cut -d\( -f1`)
  set variables = `echo $variables |sed 's/ /,/g'`
  set basename = $File:r:r
  mpirun -np 4 fregrid_parallel --input_mosaic C48_mosaic.nc --input_file $basename --interp_method conserve_order2 \
                                 --remap_file fregrid_remap_file --nlon 192 --nlat 92 --scalar_field $variables
  set latlonfiles = ($latlonfiles $basename.nc)
end
echo 'Fields interpolated to lat-lon grid exist in these files:'
foreach File ($latlonfiles)
  ls -l $cwd/$File
end
#--------------------------------------------------------------------------------------------------------

    mv ${input_dir}/* ${output_dir}/combine/${date_name}/ 
    cp -p  $workdir/logfile*.out $output_dir/logfiles/$date_name.logfile.out

    #   --- save ascii output files to local disk ---

    foreach out (`/bin/ls *.out`)
	mv $out $output_dir/logfiles/$date_name.$out
    end

    #   --- move restart files to output directory --- 

    cd $workdir/RESTART
    set resfiles = `/bin/ls *.res*`
    if ( $#resfiles > 0 ) then
	#     --- desired filename for cpio of output restart files ---	
	set restart_file = $output_dir/restart/$date_name.cpio
	if ( ! -d $restart_file:h ) mkdir -p $restart_file:h
	#     --- also save namelist and diag_table ---
	cp $workdir/{*.nml,diag_table} .
	set files = ( $resfiles input.nml diag_table )
	/bin/ls $files | cpio -ocv > $restart_file:t
	mv $restart_file:t $restart_file
	#     --- set up restart for next run ---
	if ( $irun < $runs_per_script ) then
	    mv -f *.res*  ../INPUT
	endif
    endif

    cd $workdir

    #--------------------------------------------------------------------------------------------------------

    #   --- write new reload information ---
    # for comparison with $start_analysis,  run_number = (ireload-1)*runs_per_script + irun
    set run_number = `expr $ireload \* $runs_per_script - $runs_per_script + $irun`
    echo Completed run $irun of $runs_per_script in bsub $ireload.
    set irun_prev = $irun
    @ irun++

    if ( -f $reload_file ) mv -f $reload_file $reload_file"_prev"
    
    if ( $irun <= $runs_per_script ) then
	echo "set irun         =  $irun"          >  $reload_file
    else
	@ ireload++
	echo "set irun         =  1"              >  $reload_file
    endif

    echo     "set init_cond    =  $restart_file"  >> $reload_file
    echo     "set ireload      =  $ireload"       >> $reload_file
 

end # --- loop over $irun ended ---

# rsync data_dir

rsync -uva $output_dir/combine/*  $data_dir/history
rsync -uva $output_dir/restart/*  $data_dir/restart
rsync -uva $output_dir/logfiles/* $data_dir/logfiles

rm -rf $workdir
rm -rf $scratch_dir:h

cd $exp_home/run

if ($ireload > $num_script_runs) then
  echo "Note: not resubmitting job."
else
  echo "Submitting run $ireload."
  qsub $run_script
endif

date
